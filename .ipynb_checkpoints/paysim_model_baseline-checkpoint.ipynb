{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fe845b50-d1b1-4e9a-8d84-2a7e5a960b46",
   "metadata": {},
   "source": [
    "# Context:\n",
    "\n",
    "- PaySim is a synthetic mobile money fraud dataset, in which we focus on CASH_OUT and TRANSFER, and fraud prevalence in this subset is ~0.30%.​"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4af9b8db-ae3b-433c-8ace-4c9973fa19c7",
   "metadata": {},
   "source": [
    "### Importing necessary libraries..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "40339909-dd50-4840-b04b-1e0622805b61",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "df_synth = pd.read_csv(\"data/PS_20174392719_1491204439457_log.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f78ac505-9e05-4388-b516-26ea50cc724e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['step', 'type', 'amount', 'nameOrig', 'oldbalanceOrg', 'newbalanceOrig',\n",
       "       'nameDest', 'oldbalanceDest', 'newbalanceDest', 'isFraud',\n",
       "       'isFlaggedFraud'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_synth.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "62371df5-826f-4515-ab66-57df144f4ad7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0           PAYMENT\n",
       "1           PAYMENT\n",
       "2          TRANSFER\n",
       "3          CASH_OUT\n",
       "4           PAYMENT\n",
       "             ...   \n",
       "6362615    CASH_OUT\n",
       "6362616    TRANSFER\n",
       "6362617    CASH_OUT\n",
       "6362618    TRANSFER\n",
       "6362619    CASH_OUT\n",
       "Name: type, Length: 6362620, dtype: object"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_synth.type"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "babe1fad-3f07-48dc-b7f2-c5ad84e6613b",
   "metadata": {},
   "source": [
    "#### Filtering to CASH_OUT and TRANSFER and building features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b41f9b25-79b9-47eb-bad4-59a32833eb46",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "isFraud\n",
       "0    0.997035\n",
       "1    0.002965\n",
       "Name: proportion, dtype: float64"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_synth_ct = df_synth[df_synth[\"type\"].isin([\"CASH_OUT\", \"TRANSFER\"])].copy()\n",
    "df_synth_ct[\"type_code\"] = (df_synth_ct[\"type\"] == \"TRANSFER\").astype(int)\n",
    "\n",
    "features = [\"amount\", \"oldbalanceOrg\", \"newbalanceOrig\", \"type_code\"]\n",
    "X = df_synth_ct[features]\n",
    "Y = df_synth_ct[\"isFraud\"]\n",
    "\n",
    "Y.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97124ca8-605e-4b68-8a03-811a06b9a460",
   "metadata": {},
   "source": [
    "## Train/test split and logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "709ba3eb-5d6e-4808-a7ff-e7d7e818ab60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[552381     58]\n",
      " [   958    685]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9983    0.9999    0.9991    552439\n",
      "           1     0.9219    0.4169    0.5742      1643\n",
      "\n",
      "    accuracy                         0.9982    554082\n",
      "   macro avg     0.9601    0.7084    0.7866    554082\n",
      "weighted avg     0.9980    0.9982    0.9978    554082\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=42, stratify=Y)\n",
    "\n",
    "clf = LogisticRegression(max_iter=1000)\n",
    "clf.fit(X_train, Y_train)\n",
    "\n",
    "Y_pred = clf.predict(X_test)\n",
    "\n",
    "print(confusion_matrix(Y_test, Y_pred))\n",
    "print(classification_report(Y_test, Y_pred, digits=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b3983b8-4947-48c9-9868-931239bac04b",
   "metadata": {},
   "source": [
    "#### Interpretation of the Confusion Matrix:\n",
    "\n",
    "- True negatives (TN, legit correctly flagged legit): 552381.​\n",
    "\n",
    "- False positives (FP, legit flagged as fraud): 58.​\n",
    "\n",
    "- False negatives (FN, fraud missed): 958.​\n",
    "\n",
    "- True positives (TP, fraud correctly flagged): 685.​\n",
    "\n",
    "- So out of 1643 frauds, the model catches 685 and misses 958."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "860a09a3-7670-4d77-8973-8a7d1c14ce75",
   "metadata": {},
   "source": [
    "#### The metrics further tell us:\n",
    "\n",
    "- Fraud precision ≈ 0.92: when the model says “fraud”, it is right 92% of the time, which is excellent and means few false alarms relative to the number of alerts.​\n",
    "\n",
    "- Fraud recall ≈ 0.42: the model only catches about 42% of frauds, so it still misses most fraudulent transactions.​\n",
    "\n",
    "- Overall accuracy ≈ 99.8% is not very informative here because the dataset is extremely imbalanced and we could get similar accuracy by predicting “non-fraud” almost always."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c43b4fc2-f4e5-4de8-9ecd-8426fca6d749",
   "metadata": {},
   "source": [
    "#### So, for AML, this recall is usually too low, because missing frauds is very costly, so our next steps are typically to adjust the decision threshold, reweight classes, or use a different model to trade some precision for higher recall."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2804bd81-83ae-47cb-b9df-564db955ac6a",
   "metadata": {},
   "source": [
    "#### Class-weighted logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "baacc88b-65a2-4095-a343-5f02c7b7d18b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix(weighted logistic regression):\n",
      "[[508593  43846]\n",
      " [   216   1427]]\n",
      "\n",
      "Classification report(weighted logistic regression):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9996    0.9206    0.9585    552439\n",
      "           1     0.0315    0.8685    0.0608      1643\n",
      "\n",
      "    accuracy                         0.9205    554082\n",
      "   macro avg     0.5155    0.8946    0.5097    554082\n",
      "weighted avg     0.9967    0.9205    0.9558    554082\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf_w = LogisticRegression(max_iter=1000, class_weight=\"balanced\", n_jobs=-1)\n",
    "\n",
    "clf_w.fit(X_train, Y_train)\n",
    "\n",
    "Y_pred_w = clf_w.predict(X_test)\n",
    "\n",
    "print(\"Confusion matrix(weighted logistic regression):\")\n",
    "print(confusion_matrix(Y_test, Y_pred_w))\n",
    "print()\n",
    "print(\"Classification report(weighted logistic regression):\")\n",
    "print(classification_report(Y_test, Y_pred_w, digits=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36e0f76c-431b-4827-862d-07e2a3189aeb",
   "metadata": {},
   "source": [
    "## Interpretation of Class-weighted logistic regression:\n",
    "\n",
    "- True Negatives: 508,593; \n",
    "- False Positives: 43,846; \n",
    "- False Negatives: 216; \n",
    "- True Positives: 1,427.\n",
    "\n",
    "- So we now catch about 87% of frauds (recall 0.8685) but wrongly flag around 44k legitimate transactions as fraud.\n",
    "- Fraud precision collapses to about 3%: only 3 out of 100 alerts are actually fraud, which is usually unacceptable operationally in AML, despite the high recall.\n",
    "- In other words, class_weight=\"balanced\" on its own has swung us from a “very strict” model (high precision, low recall) to an “over‑trigger‑happy” one (high recall, extremely low precision)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a866e938-e45c-4526-8bc9-731ae45b959f",
   "metadata": {},
   "source": [
    "#### Threshold tuning "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "2bddea60-198e-4e38-bdcb-b0c654a19cdd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Threshold =  0.50 ===\n",
      "[[508593  43846]\n",
      " [   216   1427]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9996    0.9206    0.9585    552439\n",
      "           1     0.0315    0.8685    0.0608      1643\n",
      "\n",
      "    accuracy                         0.9205    554082\n",
      "   macro avg     0.5155    0.8946    0.5097    554082\n",
      "weighted avg     0.9967    0.9205    0.9558    554082\n",
      "\n",
      "\n",
      "=== Threshold =  0.30 ===\n",
      "[[475526  76913]\n",
      " [   116   1527]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9998    0.8608    0.9251    552439\n",
      "           1     0.0195    0.9294    0.0381      1643\n",
      "\n",
      "    accuracy                         0.8610    554082\n",
      "   macro avg     0.5096    0.8951    0.4816    554082\n",
      "weighted avg     0.9968    0.8610    0.9224    554082\n",
      "\n",
      "\n",
      "=== Threshold =  0.20 ===\n",
      "[[439337 113102]\n",
      " [    20   1623]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     1.0000    0.7953    0.8859    552439\n",
      "           1     0.0141    0.9878    0.0279      1643\n",
      "\n",
      "    accuracy                         0.7958    554082\n",
      "   macro avg     0.5071    0.8915    0.4569    554082\n",
      "weighted avg     0.9970    0.7958    0.8834    554082\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "Y_prob_w = clf_w.predict_proba(X_test)[:, 1]\n",
    "\n",
    "def eval_threshold(threshold):\n",
    "    Y_pred_thr = (Y_prob_w >= threshold).astype(int)\n",
    "    print(f\"=== Threshold = {threshold: .2f} ===\")\n",
    "    print(confusion_matrix(Y_test, Y_pred_thr))\n",
    "    print(classification_report(Y_test, Y_pred_thr, digits=4))\n",
    "    print()\n",
    "\n",
    "for thr in [0.50, 0.30, 0.20]:\n",
    "    eval_threshold(thr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f302e0c-941b-44a0-ac92-639e6570117f",
   "metadata": {},
   "source": [
    "## Interpretation after Threshold tuning:\n",
    "\n",
    " - At 0.50: recall ≈ 0.87, precision ≈ 0.03, ~43.8k false positives. \n",
    " - We catch most frauds but almost every alert is a false alarm, which would be operationally unusable in production.\n",
    "\n",
    " - At 0.30: recall rises slightly to ≈ 0.93, precision drops further to ≈ 0.02, and false positives jump to ~76.9k, so alert volume becomes even less manageable.\n",
    "\n",
    " - At 0.20: recall is ≈ 0.99 (we miss only 20 frauds), but precision falls to ≈ 0.014 and false positives exceed 113k, which would swamp any AML team.\n",
    "\n",
    " - This nicely shows that “pushing recall towards 1” without any constraint on precision or alert volume is not realistic for fraud/AML, even though it looks good from a purely statistical viewpoint."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81e5b1d9-1154-4780-845f-95a0e944b53b",
   "metadata": {},
   "source": [
    "#### Lowering the classification threshold from 0.50 to 0.30 and 0.20 with the class‑weighted model increases fraud recall from ~0.87 to ~0.99, but precision collapses from ~3% to ~1–2%, generating tens of thousands of false alerts. This mirrors industry discussions that an effective fraud or AML system must balance recall against precision and operational alert capacity, rather than optimising a single metric in isolation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5dcec6d-ec14-49a3-8c2a-1ac336420c87",
   "metadata": {},
   "source": [
    "## Let's further try on \"Two candidate operating points\":"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "cde9c93b-3121-4b43-91c4-0a286e2c9e69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Threshold =  0.60 ===\n",
      "[[520271  32168]\n",
      " [   264   1379]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9995    0.9418    0.9698    552439\n",
      "           1     0.0411    0.8393    0.0784      1643\n",
      "\n",
      "    accuracy                         0.9415    554082\n",
      "   macro avg     0.5203    0.8905    0.5241    554082\n",
      "weighted avg     0.9967    0.9415    0.9671    554082\n",
      "\n",
      "\n",
      "=== Threshold =  0.70 ===\n",
      "[[529648  22791]\n",
      " [   333   1310]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9994    0.9587    0.9786    552439\n",
      "           1     0.0544    0.7973    0.1018      1643\n",
      "\n",
      "    accuracy                         0.9583    554082\n",
      "   macro avg     0.5269    0.8780    0.5402    554082\n",
      "weighted avg     0.9966    0.9583    0.9760    554082\n",
      "\n",
      "\n",
      "=== Threshold =  0.80 ===\n",
      "[[536554  15885]\n",
      " [   449   1194]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9992    0.9712    0.9850    552439\n",
      "           1     0.0699    0.7267    0.1276      1643\n",
      "\n",
      "    accuracy                         0.9705    554082\n",
      "   macro avg     0.5345    0.8490    0.5563    554082\n",
      "weighted avg     0.9964    0.9705    0.9825    554082\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "Y_prob_w_tcop = clf_w.predict_proba(X_test)[:, 1]\n",
    "\n",
    "def eval_threshold(threshold):\n",
    "    Y_pred_thr = (Y_prob_w_tcop >= threshold).astype(int)\n",
    "    print(f\"=== Threshold = {threshold: .2f} ===\")\n",
    "    print(confusion_matrix(Y_test, Y_pred_thr))\n",
    "    print(classification_report(Y_test, Y_pred_thr, digits=4))\n",
    "    print()\n",
    "\n",
    "for thr in [0.60, 0.70, 0.80]:\n",
    "    eval_threshold(thr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59f43a8f-8125-4e08-a062-5c07073b377f",
   "metadata": {},
   "source": [
    "## Operating points and AML interpretation:\n",
    "\n",
    "- Model A – conservative alerts (unweighted, threshold 0.50): This model achieves very high precision on frauds (~0.92) with almost no false positives, but recall is only ~0.42, so the majority of frauds are missed. This is suitable for low‑risk portfolios or early pilots where investigators will only trust the system if almost every alert is genuine.\n",
    "\n",
    "- Model B – cost‑sensitive alerts (weighted, threshold 0.80): With class_weight=\"balanced\" and a higher threshold of 0.80, fraud recall increases to ~0.73, while precision drops to ~0.07 and false positives rise to about 15.9k. This configuration would be preferred when the institution is more concerned about undetected fraud/AML cases and is willing to handle a higher but still bounded alert volume.\n",
    "\n",
    "- Overall, these two operating points illustrate that fraud and AML models must be tuned against business and regulatory constraints (cost of missed cases, investigation capacity, SLAs) rather than accuracy alone, aligning with industry guidance on precision–recall trade‑offs and threshold tuning in transaction monitoring."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "424774d7-fe42-4a64-9dd8-b5b32026fc34",
   "metadata": {},
   "source": [
    "## Limitations & next steps:\n",
    "\n",
    "- It is to note that only 4 features have been used and no time/customer history.\n",
    "- Future work could be to try tree‑based models, PRAUC/ROC‑AUC, or more realistic cost matrices, referencing how threshold optimisation and PRAUC are recommended in fraud/AML literature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf5b4377-a0e0-42a7-ab32-e419c84b1069",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22a91fdf-7639-45cd-b292-1b822792363e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b228f2d8-bfcc-4b2a-bc57-d0c3269c63f1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d405b7d8-ad2e-4df3-b5fa-ab3d423aa85d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ee2bc82-53a7-47c1-9332-24fe5cf0acf0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11084665-c797-429d-8b2d-ba5c509d9df8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5e3867e-a555-4f13-a203-9afe42c6be18",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "997324bf-4da0-46e1-a76b-5363f4ee8e05",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9322f7b-3f22-4808-8741-812153986f81",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
